{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from gpt2 import GPT2LanguageModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "\n",
    "model_name = \"345M\"\n",
    "model = GPT2LanguageModel(model_name='117M') if model_name == \"117M\" else GPT2LanguageModel(model_name='345M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n",
      "28586\n"
     ]
    }
   ],
   "source": [
    "### Clean the GPT prompts\n",
    "with open(\"GPT prompts.txt\", \"r\") as f:\n",
    "    prompts = f.readlines()\n",
    "prompts = [prompts[i].strip() for i in range(len(prompts))]\n",
    "print(len(prompts))\n",
    "print(len(list(set(prompts))))\n",
    "reduced_prompts = list(set(prompts))\n",
    "with open(\"GPT prompts stripped.txt\", \"w\") as f:\n",
    "    for p in reduced_prompts:\n",
    "        f.write(p+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Write the scripts for the cluster\n",
    "print()\n",
    "steps = 1500\n",
    "for line in range(0, 29000, steps):\n",
    "    script = f\"\"\"#!/bin/bash -l\n",
    "\n",
    "# Number of Nodes\n",
    "#SBATCH -N 1\n",
    "\n",
    "#SBATCH -t 20:00:00\n",
    "\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "#SBATCH --mail-user=kevin.trebing@ucdconnect.ie\n",
    "\n",
    "#SBATCH --job-name=prompts{line}-{line+steps}\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "# load the required modules\n",
    "module load pytorch\n",
    "\n",
    "# execute the code\n",
    "python3 probabilities.py {line}\"\"\"\n",
    "    \n",
    "    with open(f\"scripts/prompts{line}.sh\", \"w\", newline=\"\\n\") as f:\n",
    "        f.write(script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a test script\n",
    "line = 1337\n",
    "script = f\"\"\"#!/bin/bash -l\n",
    "\n",
    "# Number of Nodes\n",
    "#SBATCH -N 1\n",
    "\n",
    "#SBATCH -t 20:00:00\n",
    "\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "#SBATCH --mail-user=kevin.trebing@ucdconnect.ie\n",
    "\n",
    "#SBATCH --job-name=prompts{line}-{line+steps}\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "# load the required modules\n",
    "module load pytorch\n",
    "\n",
    "# execute the code\n",
    "python3 probabilities.py {line}\"\"\"\n",
    "    \n",
    "with open(f\"scripts/testScript{line}.sh\", \"w\", newline=\"\\n\") as f:\n",
    "    f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28577, 269)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector/dataframe from the created vectors\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Context\", \"Wordvector\"])\n",
    "fullDict = {\"Context\":[], \"Wordvector\":[]}\n",
    "files = os.listdir(\"wordvectors\")\n",
    "\n",
    "contexts = []\n",
    "wordvectors = np.zeros((len(files), 269))\n",
    "for i, context in enumerate(files):\n",
    "    with open(f\"wordvectors/{context}\", \"rb\") as f:\n",
    "        vector = pickle.load(f)\n",
    "        c, v = list(vector.items())[0]\n",
    "        contexts.append(c)\n",
    "        wordvectors[i] = np.array(v)\n",
    "#         fullDict[\"Context\"].append(c)\n",
    "#         fullDict[\"Wordvector\"].append(np.array(v))\n",
    "        \n",
    "df = pd.DataFrame(data=fullDict)\n",
    "# df[\"Wordvector\"]\n",
    "with open(\"Wordvectors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(wordvectors, f)\n",
    "with open(\"Contexts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(contexts, f)\n",
    "    \n",
    "print(wordvectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the wordvectors \n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "with open(\"Wordvectors.pkl\", \"rb\") as f:\n",
    "    wordvectors = pickle.load(f)\n",
    "with open(\"Contexts.pkl\", \"rb\") as f:\n",
    "    contexts = pickle.load(f)\n",
    "with open(\"emotions.txt\", \"r\") as f:\n",
    "    emotions = f.readlines()\n",
    "emotions = [e.strip() for e in emotions]\n",
    "\n",
    "# start_time = time.time()\n",
    "# distances = cdist(wordvectors, wordvectors, metric=\"euclidean\")\n",
    "# print(f\"Calculation with cdist took {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28577, 269)\n",
      "(28577, 28577)\n",
      "Closest\n",
      "Dist: 0.0 Context: abusing power. Emperor Caligula doesn't think that restraints are\n",
      "Dist: 0.04617828658700693 Context: spreading revolution. Oliver Cromwell doesn't think that government controls are\n",
      "Dist: 0.047542937621971725 Context: spreading revolution. Spartacus doesn't think that government controls are\n",
      "Dist: 0.05607030256286821 Context: spreading revolution. Che Guevara doesn't think that government controls are\n",
      "Dist: 0.06456561063155321 Context: running a communist country. Joseph Stalin doesn't think that lower taxes are\n",
      "Dist: 0.06495946339172486 Context: promoting liberal values. Voltaire doesn't think that state controls are\n",
      "Dist: 0.06762592070330024 Context: promoting pacifism. Martin Luther King doesn't think that nuclear weapons are\n",
      "Dist: 0.06831838544827147 Context: spreading revolution. Leon Trotsky doesn't think that government controls are\n",
      "Dist: 0.06920538616567201 Context: publishing soft pornography. Hugh Hefner doesn't think that censorship is\n",
      "Dist: 0.07042895604755678 Context: instigating rebellion. Sitting Bull doesn't think that censorship is\n",
      "\n",
      "Farthest\n",
      "Dist: 1.076764597964839 Context: walking like a man. John Wayne thinks that chivalry is\n",
      "Dist: 1.076456114577615 Context: spying on girls. George McFly doesn't think that chivalry is\n",
      "Dist: 1.0663052539893645 Context: defending the weak. Mad Max Rockatansky thinks that chivalry is\n",
      "Dist: 1.0610871891032543 Context: defending the weak. Captain America thinks that chivalry is\n",
      "Dist: 1.059632557295926 Context: battling the forces of darkness. Hellboy thinks that chivalry is\n",
      "Dist: 1.0470615644619292 Context: spying on girls. Norman Bates doesn't think that chivalry is\n",
      "Dist: 1.0422268208652432 Context: defending the innocent. Perry Mason thinks that chivalry is\n",
      "Dist: 1.0421055754074873 Context: making modern art. Jeff Koons doesn't think that classicism is\n",
      "Dist: 1.038135371738885 Context: ranting about conservatives. Brian Griffin doesn't think that conservatism is\n",
      "Dist: 1.0360054594042238 Context: defending the weak. Catwoman thinks that chivalry is\n",
      "0.9809337071574086\n",
      "[[128 232 133 ...   4  48   5]\n",
      " [267 257 128 ... 231  57  35]\n",
      " [128 148 126 ... 239  35  57]\n",
      " ...\n",
      " [192 198 262 ...  69  29  35]\n",
      " [133 145 257 ...   1   4  69]\n",
      " [128 244 207 ...   5  29   4]]\n",
      "[[  5  48   4 ... 133 232 128]\n",
      " [ 35  57 231 ... 128 257 267]\n",
      " [ 57  35 239 ... 126 148 128]\n",
      " ...\n",
      " [ 35  29  69 ... 262 198 192]\n",
      " [ 69   4   1 ... 257 145 133]\n",
      " [  4  29   5 ... 207 244 128]]\n",
      "[   1    2    3 1337    5    6    7    8    9]\n",
      "[   9    8    7    6    5 1337    3    2    1]\n",
      "[9 8 7 6 5 4 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getDistanceToOthers(vector, vectorMatrix, contexts, metric=\"euclidean\"):\n",
    "    distanceToOthers = cdist([vector], vectorMatrix, metric=\"euclidean\")[0]\n",
    "    order = np.argsort(distanceToOthers)\n",
    "    n = 10\n",
    "    # Closest\n",
    "    print(\"Closest\")\n",
    "    for ind in order[:n]:\n",
    "        print(f\"Dist: {distanceToOthers[ind]} Context: {contexts[ind]}\")\n",
    "    print()\n",
    "    print(\"Farthest\")\n",
    "    for ind in order[::-1][:n]:\n",
    "        print(f\"Dist: {distanceToOthers[ind]} Context: {contexts[ind]}\")\n",
    "    \n",
    "\n",
    "print(wordvectors.shape)\n",
    "print(distances.shape)\n",
    "\n",
    "vectorToCompare = wordvectors[3]\n",
    "getDistanceToOthers(vectorToCompare, wordvectors, contexts)\n",
    "\n",
    "\n",
    "ascInds = np.argsort(wordvectors, axis=1)\n",
    "descInds = np.array([arr[::-1] for arr in ascInds])\n",
    "a = np.array([1,2,3,4,5,6,7,8,9])\n",
    "b = a[::-1]\n",
    "c = np.array(a[::-1])\n",
    "print(np.max(wordvectors))\n",
    "print(ascInds)\n",
    "print(descInds)\n",
    "\n",
    "a[3] = 1337\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Clean writing prompts from artefacts such as \"[WP]\" and edits like \"thanks for the gold kind stranger!\"\n",
    "import re\n",
    "\n",
    "with open(\"data/wpdump.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    writingprompts = f.readlines()\n",
    "# print(writingprompts[:10])\n",
    "\n",
    "with open(\"data/writingprompts_cleaned.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(writingprompts):\n",
    "        if (\"[WP]\" in line) or (\"<|endoftext|>\" in line):\n",
    "            lineToSave = line\n",
    "        else:\n",
    "            # remove lines with /r/ or u/ or www. or EDIT\n",
    "            if (bool(re.search(r\"www\\..*\\.\", line)) or \n",
    "                bool(re.search(r\"https?:\", line)) or \n",
    "                bool(re.search(r\"r\\/(\\w|\\d)+\", line)) or \n",
    "                bool(re.search(r\"\\b(([E|e]dit)|(EDIT))\\**[:|\\s]\", line)) or\n",
    "                bool(re.search(r\"u\\/(\\w|\\d)+\", line))):\n",
    "                continue\n",
    "            # Remove weird \"no space characters\"\n",
    "            lineToSave = line.replace(\"&#x200B;\", \"\")\n",
    "            # Remove multiple linebreaks and spaces\n",
    "            lineToSave = re.sub(r\"\\n+\", \" \", lineToSave)\n",
    "#             lineToSave = re.sub(\"(\\\\[_|\\-])+\", \"\", lineToSave)\n",
    "        f.write(lineToSave)\n",
    "\n",
    "with open(\"data/writingprompts_cleaned.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    strings = f.readlines()\n",
    "    fullString = \"\".join(strings)\n",
    "    fullString = re.sub(r\"[\\*|\\-|_]+\\s*<\\|endoftext\\|>\", \"<|endoftext|>\", fullString)\n",
    "    fullString = re.sub(r\"(\\\\_)+\", \"\", fullString)\n",
    "    fullString = re.sub(r\"(\\\\\\-)+\", \"\", fullString)\n",
    "    fullString = re.sub(r\"\\bStory:\", \"\\n\", fullString)\n",
    "    fullString = re.sub(r\"\\bPrompt:\", \"[WP]\", fullString)\n",
    "\n",
    "    # Get rid of boldening and section-limiter (from reddit formatting)\n",
    "    fullString = fullString.replace(\"*\", \"\")\n",
    "    fullString = fullString.replace(\"---\", \"\")\n",
    "    # Get rid of double whitespaces (but not newlines)\n",
    "    fullString = re.sub(r\"[^\\S\\r\\n]{2,}\", \" \", fullString)\n",
    "    with open(\"data/writingprompts_cleaned_fully.txt\", \"w\", encoding=\"utf-8\") as f2:\n",
    "        f2.write(fullString)\n",
    "    \n",
    "# Remove everything between \"---\", \"***\", \"___\" and \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a script for training gpt-2 on the GPU node\n",
    "\n",
    "script = f\"\"\"#!/bin/bash -l\n",
    "\n",
    "# Number of Nodes\n",
    "#SBATCH -N 1\n",
    "\n",
    "# Request GPU node\n",
    "#SBATCH --partition=csgpu\n",
    "\n",
    "#SBATCH -t 00:10:00\n",
    "\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "#SBATCH --mail-user=kevin.trebing@ucdconnect.ie\n",
    "\n",
    "#SBATCH --job-name=testGPT2\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "# load the required modules\n",
    "module load tensorflowgpu\n",
    "\n",
    "# execute the code\n",
    "python3 train.py --model_name 345M --run_name run345M --dataset data\\writingprompts.npz --batch_size 1 --top_p 0.9 --save_every 2500 --sample_every 1000\"\"\"\n",
    "    \n",
    "with open(f\"scripts/testGPU.sh\", \"w\", newline=\"\\n\") as f:\n",
    "    f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"genies. Edit: First Reddit gold! Thank \"\n",
    "print(bool(re.search(r\"\\b(([E|e]dit)|(EDIT))[:|\\s]\", line)))\n",
    "print(bool(re.search(\"edit\", line)))\n",
    "bool(re.search(r\"\\b(([E|e]dit)|(EDIT))[:|\\s]\", line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating story prompts from storyville\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
