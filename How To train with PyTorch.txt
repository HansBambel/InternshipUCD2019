### Set-up ###
A) Without Docker
1. Clone this repository
2. Have python installed
3. Install the requirements of the requirements.txt
	a. This can be done with anaconda or pip (e.g.:pip install tqdm) (I used a conda environment "gpt-2" that was a clone of the basic python env) "conda create --name gpt-2 --clone base"
	b. Install pytorch-transformers (pip install pytorch-transformers)
		Note: On the cluster we dont have permission to install packages --> use "pip3 --user install pytorch-transformers" to install packages
	
B) With Docker
1. Install Docker
2. Clone this repository
3. Build the docker image: "docker build --tag=transformers ."
4. Run an interactive and detached image: "docker run -it -d transformers"
	a: To get the running containers: "docker ps" -a shows all (also stopped containers)
	b. To copy files to the running docker image: "docker cp <folder/file-to-copy> <container-name>:/gpt-2"
	c. To copy files from the running docker image to the host: "docker cp <container-name>:/gpt-2 ."
5. To enter the running docker image: "docker exec -it <container-name>"

#### Convert from Tensorflow checkpoint to PyTorch ####
1. Clone the repository https://github.com/huggingface/pytorch-transformers.git
2. Enter repository
3. "pytorch_transformers gpt2 $OPENAI_GPT2_CHECKPOINT_PATH $PYTORCH_DUMP_OUTPUT [OPENAI_GPT2_CONFIG]
	e.g.: "python pytorch_transformers gpt2 C:\Users\AI-Machine\Documents\gpt-2\checkpoint\writingprompts117M C:\Users\AI-Machine\Documents\nextWordPrediction\models"
	Note: I needed to remove the . before the import in the __main__.py line 72 to make it work

#### Training ####
python finetuneGPT2.py --model_name gpt2 --do_train --do_eval --train_dataset $ROC_STORIES_DIR/cloze_test_val__spring2016/cloze_test_ALL_val.csv --eval_dataset $ROC_STORIES_DIR/cloze_test_test__spring2016/cloze_test_ALL_test.csv --output_dir ../log --train_batch_size 16